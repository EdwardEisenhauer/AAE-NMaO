
The method decomposes the matrix $\matr{A}$ into its lower triangular part $\matr{L}$, its diagonal $\matr{D}$, and its upper triangular part $\matr{U}$, 
such that $\matr{A} = \matr{L} + \matr{D} + \matr{U}$. The iteration process then uses the current and previous iterates to form the new solution vector.

The iterative step of the Gauss-Seidel method can be expressed as:
\begin{equation*}
    x^{(k+1)}_i = \frac{1}{a_{ii}}\left(b_i - \sum_{j=1}^{i-1} a_{ij} x^{(k+1)}_j - \sum_{j=i+1}^n a_{ij} x^{(k)}_j \right), \quad i = 1, 2, \ldots, n,
\end{equation*}
where:
\begin{itemize}
    \item $x^{(k)}_j$ denotes the $j$-th component of the solution vector at the $k$-th iteration.
    \item $a_{ij}$ is the element of $A$ in the $i$-th row and $j$-th column.
    \item $b_i$ is the $i$-th component of the vector $b$.
    \item The iteration for each $x^{(k+1)}_i$ uses the most recently updated values of $x^{(k+1)}$.
\end{itemize}

The Gauss-Seidel method updates each entry of the vector $x$ in sequence, directly substituting the newly computed values into subsequent equations within the same iteration. This typically allows the Gauss-Seidel method to converge faster than the Jacobi method, which updates all values based on the previous iteration's data only.

Convergence is guaranteed if the matrix $\matr{A}$ is diagonally dominant or positive definite. 
The convergence criterion is often set as the relative change in the solution vector between iterations falling below a specified tolerance.
